{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gf26-KARRd4t"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# The relative path of the folder containing your data\n",
    "path_data = './data'\n",
    "filename = 'usagers-2022.csv'\n",
    "url = 'https://www.data.gouv.fr/fr/datasets/r/62c20524-d442-46f5-bfd8-982c59763ec8'\n",
    "\n",
    "def load_file(filename, path_data, url):\n",
    "    filepath = os.path.join(path_data, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        print(f'The file {filename} already exists in folder {path_data}/.')\n",
    "    else:\n",
    "        r = requests.get(url)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        print(f'Downloaded file {filename} in folder {path_data}/.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jE9Qg0waRd4y",
    "outputId": "2f7cdf21-5e37-4c32-d969-66684c3e5b62"
   },
   "outputs": [],
   "source": [
    "# The relative path of the folder containing your data\n",
    "path_data = './data'\n",
    "filename = 'usagers-2022.csv'\n",
    "url = 'https://www.data.gouv.fr/fr/datasets/r/62c20524-d442-46f5-bfd8-982c59763ec8'\n",
    "\n",
    "load_file(filename, path_data, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_ScYsVuRd41",
    "outputId": "a7728be3-c881-4d20-d0b1-a82f51f5e7dd"
   },
   "outputs": [],
   "source": [
    "filename = 'vehicules-2022.csv'\n",
    "url = 'https://www.data.gouv.fr/fr/datasets/r/c9742921-4427-41e5-81bc-f13af8bc31a0'\n",
    "\n",
    "load_file(filename, path_data, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1U8I0fCRd42",
    "outputId": "cffe0493-bffd-4251-cb0b-b4fd3e879b02"
   },
   "outputs": [],
   "source": [
    "filename = 'carcteristiques-2022.csv'\n",
    "url = 'https://www.data.gouv.fr/fr/datasets/r/5fc299c0-4598-4c29-b74c-6a67b0cc27e7'\n",
    "\n",
    "\n",
    "load_file(filename, path_data, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "908hwJRFRd42",
    "outputId": "43efee3c-632d-4560-cf3e-84ea71be8159"
   },
   "outputs": [],
   "source": [
    "filename = 'lieux-2022.csv'\n",
    "url = 'https://www.data.gouv.fr/fr/datasets/r/a6ef711a-1f03-44cb-921a-0ce8ec975995'\n",
    "\n",
    "load_file(filename, path_data, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "peca0f8VRd43",
    "outputId": "7a3dd4b8-fea2-4641-f820-bc4bbff1de41"
   },
   "outputs": [],
   "source": [
    "filename = 'usagers-2021.csv'\n",
    "url = 'https://www.data.gouv.fr/fr/datasets/r/ba5a1956-7e82-41b7-a602-89d7dd484d7a'\n",
    "\n",
    "load_file(filename, path_data, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqO6bGODRd44",
    "outputId": "4fe101f1-2db4-40e8-ba76-29d4a95e8e02"
   },
   "outputs": [],
   "source": [
    "filename = 'vehicules-2021.csv'\n",
    "url = 'https://www.data.gouv.fr/fr/datasets/r/0bb5953a-25d8-46f8-8c25-b5c2f5ba905e'\n",
    "\n",
    "load_file(filename, path_data, url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pBinu8uMRd45",
    "outputId": "e59e828a-476b-44ca-f035-e205a27db203"
   },
   "outputs": [],
   "source": [
    "filename = 'lieux-2021.csv'\n",
    "url = 'https://www.data.gouv.fr/fr/datasets/r/8a4935aa-38cd-43af-bf10-0209d6d17434'\n",
    "\n",
    "load_file(filename, path_data, url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrRIJ5Y2Rd46",
    "outputId": "44fe084f-f97c-4f51-96ea-c056eb84555c"
   },
   "outputs": [],
   "source": [
    "filename = 'carcteristiques-2021.csv'\n",
    "url = 'https://www.data.gouv.fr/fr/datasets/r/85cfdc0c-23e4-4674-9bcd-79a970d7269b'\n",
    "\n",
    "load_file(filename, path_data, url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation de la Session Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLlg1A5FRd47",
    "outputId": "8ef9f4b8-b9d4-4f35-a39a-d0befb381631"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "\n",
    "\n",
    "\n",
    "types = ['usagers', 'lieux', 'vehicules', 'carcteristiques']\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairie de fonction utiles au nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nriESrgoRd49",
    "outputId": "65d5e0a2-5b9a-4ed1-af69-f2d2849e318d"
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import *\n",
    "import re\n",
    "\n",
    "def bad_float_convertion(x, col):\n",
    "    dk = x.withColumn(col, regexp_replace(col, \",\", \".\"))\n",
    "    dk = dk.withColumn(col, dk[col].cast(DoubleType()))\n",
    "    return dk\n",
    "\n",
    "def bad_date_convertion(x, col_day, col_month, col_year, col_hour):\n",
    "    dk = x.withColumn(\"date_str\",\n",
    "                        concat(x[col_year], lit(\"-\"), x[col_month], lit(\"-\"), x[col_day], lit(\" \"), x[col_hour]))   \n",
    "    dk = dk.withColumn(\"date_complete\", to_timestamp(dk[\"date_str\"], \"yyyy-MM-dd HH:mm\"))\n",
    "    dk = dk.drop(\"date_str\")\n",
    "    dk = dk.drop(col_year)\n",
    "    dk = dk.drop(col_month)\n",
    "    dk = dk.drop(col_day)\n",
    "    dk = dk.drop(col_hour)\n",
    "    return dk   \n",
    "\n",
    "def replace_with (df, column, value, new_value):\n",
    "    return df.withColumn(column, when(col(column).isNull() | (col(column) == value), new_value).otherwise(col(column)))\n",
    "\n",
    "def replace_empty_with_value(df, column, new_value):\n",
    "    return replace_with(df, column, \"\", new_value)\n",
    "\n",
    "def replace_empty_with_zero(df, value):\n",
    "    return replace_empty_with_value(df, value, \"0\")\n",
    "\n",
    "def replace_empty_with_null(df, column_name):\n",
    "    return replace_empty_with_value(df, column_name, None)\n",
    "\n",
    "def replace_minus_one_with_null(df, column_name):\n",
    "    return replace_with(df, column_name, \"-1\", None)\n",
    "\n",
    "def trim_cast_integer(df, column):\n",
    "    return df.withColumn(column, trim(df[column]).cast(IntegerType()))\n",
    "\n",
    "def trim_replace_minus_one (df, column):\n",
    "    res = trim_cast_integer(df, column)\n",
    "    res = replace_minus_one_with_null(res, column)\n",
    "    return res\n",
    "\n",
    "def get_type_columns(df , type_):\n",
    "    integer_columns = [col_name for col_name, col_type in df.dtypes if col_type == type_]\n",
    "    return integer_columns\n",
    "\n",
    "def get_integer_columns(df):\n",
    "    return get_type_columns(df, \"int\")\n",
    "\n",
    "def remove_spaces(s):\n",
    "    return re.sub(r'\\s+', '', s)\n",
    "\n",
    "def get_unique_column_values(df, column_name):\n",
    "   \n",
    "    unique_values_df = df.select(column_name).distinct()\n",
    "    unique_values_list = [row[column_name] for row in unique_values_df.collect()]\n",
    "    return unique_values_list\n",
    "\n",
    "def show_unique_column_values(df, column_name):\n",
    "    unique_num_acc_values = df.select(column_name).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    print(\"unique :\", unique_num_acc_values)\n",
    "\n",
    "def remove_spaces_column(df, column_name):\n",
    "    remove_spaces_udf = udf(remove_spaces, StringType())\n",
    "    return df.withColumn(column_name, remove_spaces_udf(df[column_name]).cast(LongType()))\n",
    "\n",
    "spark.conf.set(\"spark.sql.parquet.int96RebaseModeInWrite\", \"CORRECTED\")\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructeur de dataframes \"caracteristiques\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: les variables qui sont soit une valeur soit une valeur vide sont directement converti.\n",
    "Mais les variables catégoriques sont nettoyé (truncate et -1 ou \"\" changé en NULL par exemple) et puis converti. Une valeur hors des catégories spécifiées peuvent être intéressantes à étudier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caracteristique_df(path):\n",
    "    caracteristique_schema = StructType([\n",
    "    StructField(\"Num_Acc\", LongType(), False),\n",
    "    StructField(\"jour\", StringType(), False),\n",
    "    StructField(\"mois\", StringType(), False),\n",
    "    StructField(\"an\", StringType(), False),  \n",
    "    StructField(\"hrmn\", StringType(), False),  \n",
    "    StructField(\"lum\", StringType(), True),  \n",
    "    StructField(\"dep\", StringType(), True),  \n",
    "    StructField(\"com\", StringType(), True),      \n",
    "    StructField(\"agg\", IntegerType(), True), \n",
    "    StructField(\"int\", IntegerType(), True),  \n",
    "    StructField(\"atm\", IntegerType(), True),  \n",
    "    StructField(\"col\", StringType(), True),      \n",
    "    StructField(\"adr\", StringType(), True),\n",
    "    StructField(\"lat\", StringType(), True),\n",
    "    StructField(\"long\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "\n",
    "\n",
    "    df_caract = spark.read.csv(path, header=True, sep=';', schema=caracteristique_schema)\n",
    "\n",
    "    df_caract = bad_float_convertion(df_caract, 'lat')\n",
    "    df_caract = bad_float_convertion(df_caract, 'long')\n",
    "    df_caract = bad_date_convertion(df_caract, \"jour\", \"mois\", \"an\", \"hrmn\")\n",
    "    df_caract = df_caract.withColumn(\"agg\", \n",
    "                                           when(col(\"agg\") == 1, True)\n",
    "                                           .when(col(\"agg\") == 2, False)\n",
    "                                           .cast(BooleanType()))\n",
    "    \n",
    "    dk = get_integer_columns(df_caract)\n",
    "    for column in dk:\n",
    "        df_caract = replace_minus_one_with_null(df_caract, column)\n",
    "    df_caract = trim_replace_minus_one(df_caract, \"col\")\n",
    "\n",
    "    return df_caract\n",
    "\n",
    "df_caract = caracteristique_df('./data/carcteristiques-2022.csv')\n",
    "df_caract.show(5)\n",
    "df_caract.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructeur de dataframes \"usagers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KlndpJlDRd49",
    "outputId": "ec92373e-006f-4d26-ac28-4c86f33fb33c"
   },
   "outputs": [],
   "source": [
    "def usager_df(path):\n",
    "\n",
    "    schema_usager = StructType([\n",
    "        StructField(\"Num_Acc\", LongType(), True),\n",
    "        StructField(\"id_usager\", StringType(), False),\n",
    "        StructField(\"id_vehicule\", StringType(), False),\n",
    "        StructField(\"num_veh\", StringType(), False),\n",
    "        StructField(\"place\", IntegerType(), False),\n",
    "        StructField(\"catu\", StringType(), False),\n",
    "        StructField(\"grav\", StringType(), False),\n",
    "        StructField(\"sexe\", StringType(), False),\n",
    "        StructField(\"an_nais\", IntegerType(), False),\n",
    "        StructField(\"trajet\", StringType(), True),\n",
    "        StructField(\"secu1\", StringType(), True),\n",
    "        StructField(\"secu2\", StringType(), True),\n",
    "        StructField(\"secu3\", StringType(), True),\n",
    "        StructField(\"locp\", StringType(), True),\n",
    "        StructField(\"actp\", StringType(), True),\n",
    "        StructField(\"etatp\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    df_usager = spark.read.csv(path, header=True, sep=';', schema=schema_usager) \n",
    "    df_usager = df_usager.withColumn(\"sexe\", \n",
    "                                            when(col(\"sexe\") == '1', 0)\n",
    "                                            .when(col(\"sexe\") == '2', 1)\n",
    "                                            .cast(IntegerType()))\n",
    "\n",
    "    to_remove_space = [\"id_usager\", \"id_vehicule\"]\n",
    "    for column in to_remove_space:\n",
    "        df_usager = remove_spaces_column(df_usager, column)\n",
    "\n",
    "    to_trim_replace_minus_one = [\"secu1\", \"secu2\", \"trajet\", \"locp\", \"actp\", \"etatp\", \"secu3\", \"grav\"]\n",
    "    for column in to_trim_replace_minus_one:\n",
    "        df_usager = trim_replace_minus_one(df_usager, column)\n",
    "    \n",
    "    return df_usager\n",
    "\n",
    "\n",
    "df_usager = usager_df('./data/usagers-2022.csv')\n",
    "df_usager.show(5)\n",
    "df_usager.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructeur de dataframes \"lieux\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6wUG7Gu65XI",
    "outputId": "bf3f2184-ccda-4831-c2dd-70516edd9feb"
   },
   "outputs": [],
   "source": [
    "def lieux_df(path):\n",
    "    schema_lieux = StructType([\n",
    "        StructField(\"Num_Acc\", StringType(), True),\n",
    "        StructField(\"catr\", StringType(), True),\n",
    "        StructField(\"voie\", StringType(), True),\n",
    "        StructField(\"v1\", StringType(), True),\n",
    "        StructField(\"v2\", StringType(), True),\n",
    "        StructField(\"circ\", StringType(), True),\n",
    "        StructField(\"nbv\", StringType(), True),\n",
    "        StructField(\"vosp\", StringType(), True),\n",
    "        StructField(\"prof\", StringType(), True),\n",
    "        StructField(\"pr\", StringType(), True),\n",
    "        StructField(\"pr1\", StringType(), True),\n",
    "        StructField(\"plan\", StringType(), True),\n",
    "        StructField(\"lartpc\", IntegerType(), True),\n",
    "        StructField(\"larrout\", IntegerType(), True),\n",
    "        StructField(\"surf\", StringType(), True),\n",
    "        StructField(\"infra\", StringType(), True),\n",
    "        StructField(\"situ\", StringType(), True),\n",
    "        StructField(\"vma\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    df_lieux = spark.read.csv(path, header=True, sep=';', schema=schema_lieux)\n",
    "    to_replace_empty = [\"voie\", \"v1\", \"v2\", \"lartpc\"]\n",
    "    for column in to_replace_empty:\n",
    "        df_lieux = replace_empty_with_null(df_lieux, column)\n",
    "        df_lieux = replace_with(df_lieux, column, \"N/A\", None)\n",
    "\n",
    "    to_trim_replace_minus_one = [\"catr\", \"circ\", \"nbv\", \"vosp\", \"prof\", \"pr\", \"pr1\", \"plan\", \"surf\", \"infra\", \"situ\", \"vma\", \"v1\"]\n",
    "    for column in to_trim_replace_minus_one:\n",
    "        df_lieux = trim_replace_minus_one(df_lieux, column)\n",
    "\n",
    "    return df_lieux\n",
    "\n",
    "df_lieux = lieux_df('./data/lieux-2022.csv')\n",
    "df_lieux.show(200)\n",
    "df_lieux.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructeur de dataframes \"vehicule\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGhDxzRvRd4-",
    "outputId": "5aeaf740-570d-4e73-b18a-0ced8108c9a0"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def vehicule_df(path):\n",
    "    schema_vehicule = StructType([\n",
    "        StructField(\"Num_Acc\", LongType(), True),\n",
    "        StructField(\"id_vehicule\", StringType(), False),\n",
    "        StructField(\"num_veh\", StringType(), False),\n",
    "        StructField(\"senc\", IntegerType(), False),\n",
    "        StructField(\"catv\", IntegerType(), False),\n",
    "        StructField(\"obs\", IntegerType(), False),\n",
    "        StructField(\"obsm\", IntegerType(), False),\n",
    "        StructField(\"choc\", IntegerType(), False),\n",
    "        StructField(\"manv\", IntegerType(), False),\n",
    "        StructField(\"motor\", IntegerType(), False),\n",
    "        StructField(\"occutc\", StringType(), False),\n",
    "    ])\n",
    "\n",
    "    df_veh = spark.read.csv(path, header=True, sep=';', schema=schema_vehicule)\n",
    "    df_veh = replace_empty_with_zero(df_veh, \"occutc\")\n",
    "    df_veh = df_veh.withColumn(\"occutc\", df_veh[\"occutc\"].cast(IntegerType()))     \n",
    "    df_veh = remove_spaces_column(df_veh, \"id_vehicule\")\n",
    "    \n",
    "    return df_veh\n",
    "\n",
    "\n",
    "df_veh = vehicule_df('./data/vehicules-2022.csv')\n",
    "df_veh.show(5)\n",
    "df_veh.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction tableau data_frames gardant les dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2021', '2022']\n",
    "data_frames = {}\n",
    "for y in years:\n",
    "    for type_ in types:\n",
    "        df_name = type_ + ('-') + y\n",
    "        filename = df_name + '.csv'\n",
    "        filepath = os.path.join(path_data, filename)\n",
    "        prefix = df_name.split('-')[0]\n",
    "        if prefix == 'usagers':\n",
    "            data_frames [df_name] = usager_df(filepath)\n",
    "        elif prefix == 'lieux':\n",
    "            data_frames [df_name] = lieux_df(filepath)\n",
    "        elif prefix == 'vehicules':\n",
    "            data_frames [df_name] = vehicule_df(filepath)\n",
    "        elif prefix == 'carcteristiques':\n",
    "            data_frames [df_name] = caracteristique_df(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des dataframes union de 2021-2O22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJgQMdoIRd4-",
    "outputId": "4f90b3f6-98ec-4096-bdfc-dcfdebbf66f9"
   },
   "outputs": [],
   "source": [
    "lieux_22 = data_frames['lieux-2022']\n",
    "lieux_21 = data_frames['lieux-2021']\n",
    "\n",
    "lieux = lieux_21.union(lieux_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usagers_22 = data_frames['usagers-2022']\n",
    "usagers_21 = data_frames['usagers-2021']\n",
    "\n",
    "usagers = usagers_21.union(usagers_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicules_22 = data_frames['vehicules-2022']\n",
    "vehicules_21 = data_frames['vehicules-2021']\n",
    "\n",
    "vehicules = vehicules_21.union(vehicules_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caracteristiques_22 = data_frames['carcteristiques-2022']\n",
    "caracteristiques_21 = data_frames['carcteristiques-2021']\n",
    "\n",
    "caracteristiques = caracteristiques_21.union(caracteristiques_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(df, numerical_columns):\n",
    "    statistics = {}\n",
    "    for col_name in numerical_columns:\n",
    "        column_stats = {}\n",
    "        column_stats['Mean'] = df.selectExpr(f'avg({col_name})').collect()[0][0]\n",
    "        column_stats['Median'] = df.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "        column_stats['Q1'], column_stats['Q3'] = df.approxQuantile(col_name, [0.25, 0.75], 0.01)\n",
    "        column_stats['Standard Deviation'] = df.selectExpr(f'stddev_pop({col_name})').collect()[0][0]\n",
    "        column_stats['Skewness'] = df.selectExpr(f'skewness({col_name})').collect()[0][0]\n",
    "        column_stats['Kurtosis'] = df.selectExpr(f'kurtosis({col_name})').collect()[0][0]\n",
    "        column_stats['IQR'] = column_stats['Q3'] - column_stats['Q1']\n",
    "        statistics[col_name] = column_stats\n",
    "\n",
    "    return statistics\n",
    "\n",
    "def show_statistics(statistics):\n",
    "    print(\"Statistiques des colonnes numériques:\")\n",
    "    for col_name, stats in statistics.items():\n",
    "        print(f\"Colonne: {col_name}\")\n",
    "        for stat_name, value in stats.items():\n",
    "            print(f\"{stat_name}: {value}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usagers_statistics = compute_statistics(usagers,['trajet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_statistics(usagers_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Extract column names and statistics\n",
    "def plot_statistics(statistics):\n",
    "    column_names = list(statistics.keys())\n",
    "    mean_values = [stats['Mean'] for stats in statistics.values()]\n",
    "    median_values = [stats['Median'] for stats in statistics.values()]\n",
    "    q1_values = [stats['Q1'] for stats in statistics.values()]\n",
    "    q3_values = [stats['Q3'] for stats in statistics.values()]\n",
    "    std_dev_values = [stats['Standard Deviation'] for stats in statistics.values()]\n",
    "    skewness_values = [stats['Skewness'] for stats in statistics.values()]\n",
    "    kurtosis_values = [stats['Kurtosis'] for stats in statistics.values()]\n",
    "    iqr_values = [stats['IQR'] for stats in statistics.values()]\n",
    "\n",
    "    # Create traces\n",
    "    mean_trace = go.Bar(x=column_names, y=mean_values, name='Mean')\n",
    "    median_trace = go.Bar(x=column_names, y=median_values, name='Median')\n",
    "    q1_trace = go.Bar(x=column_names,y=q1_values, name='Q1')\n",
    "    q3_trace = go.Bar(x=column_names,y=q3_values, name='Q3')\n",
    "    std_dev_trace = go.Bar(x=column_names,y=std_dev_values, name='Standard Deviation')\n",
    "    skewness_trace = go.Bar(x=column_names,y=skewness_values, name='Skewness')\n",
    "    kurtosis_trace = go.Bar(x=column_names,y=kurtosis_values, name='Kurtosis')\n",
    "    iqr_trace = go.Bar(x=column_names,y=iqr_values, name='IQR')\n",
    "\n",
    "    # Create layout\n",
    "    layout = go.Layout(title='Box Plot des colonnes numériques', xaxis=dict(title='Colonne'),\n",
    "                   yaxis=dict(title='Valeur'))\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure(data=[mean_trace, median_trace, q1_trace, q3_trace, std_dev_trace, skewness_trace, kurtosis_trace, iqr_trace], layout=layout)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lieux_statistics = compute_statistics(lieux,['pr1'])\n",
    "plot_statistics(lieux_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap de la répartition des accidents de la route selon l'heure et le jour de la semaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "\n",
    "\n",
    "df_c = caracteristiques\n",
    "df_v = vehicules.select(\"Num_Acc\", \"obsm\")\n",
    "df_pieton = df_v.where(col(\"obsm\") == 1)\n",
    "\n",
    "\n",
    "df_caracteristique_time = df_c.withColumn(\"day\", dayofweek(\"date_complete\")).withColumn(\"hour\", hour(\"date_complete\")).withColumn(\"minute\", minute(\"date_complete\")).withColumn(\"month\", month(\"date_complete\")).select(\"Num_Acc\",\"day\", \"hour\", \"minute\", \"month\")\n",
    "df_pieton = df_pieton.join(df_caracteristique_time, \"Num_Acc\")\n",
    "\n",
    "\n",
    "name_pieton = 'Répartition des accidents impliquant des piétons par jour de la semaine et heure de la journée'\n",
    "\n",
    "def plot_day(df, name):\n",
    "    df_pd = df.toPandas()\n",
    "\n",
    "    fig = px.density_heatmap(df_pd, x='hour', y='day',\n",
    "                            title=name,\n",
    "                            labels={'hour': 'Heure de la journée', 'day': 'Jour de la semaine'},\n",
    "                            nbinsx=24, nbinsy=7, marginal_x='histogram', marginal_y='histogram')\n",
    "\n",
    "    jour_labels = {1: 'Lundi', 2: 'Mardi', 3: 'Mercredi', 4: 'Jeudi', 5: 'Vendredi', 6: 'Samedi', 7: 'Dimanche'}\n",
    "    fig.update_yaxes(ticktext=[jour_labels[i] for i in range(1, 8)], tickvals=list(range(1, 8)))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_day(df_pieton, name_pieton)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphique de la répartition des accidents sur les de l'année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_month(df):\n",
    "   df_monthly = df.groupBy('month').count().orderBy('month')\n",
    "   month_names = {\n",
    "      1: 'Janvier', 2: 'Février', 3: 'Mars', 4: 'Avril', 5: 'Mai', 6: 'Juin',\n",
    "      7: 'Juillet', 8: 'Août', 9: 'Septembre', 10: 'Octobre', 11: 'Novembre', 12: 'Décembre'\n",
    "   }\n",
    " \n",
    "   df_monthly_pd = df_monthly.toPandas()\n",
    "\n",
    "   df_monthly_pd['month'] = df_monthly_pd['month'].map(month_names)\n",
    "\n",
    "   \n",
    "   fig = px.line(df_monthly_pd, x='month', y='count',\n",
    "               title='Répartition des accidents par mois',\n",
    "               labels={'month': 'Mois', 'count': 'Nombre d\\'accidents'})\n",
    "   fig.show()\n",
    "\n",
    "plot_month(df_caracteristique_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphique de la distribution de l'âge des usagers qui ont eu un accident dans une route de métropole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annee_acc = caracteristiques.select(\"Num_Acc\", \"date_complete\").withColumn(\"year\", year(\"date_complete\")).drop(\"date_complete\")\n",
    "\n",
    "joined_usagers_lieux_df = usagers.join(lieux, 'Num_Acc')\n",
    "usagers_urbains = joined_usagers_lieux_df.select(\"Num_Acc\", \"id_usager\", \"sexe\",\"An_nais\").where(\"catr=7\")\n",
    "usagers_urbains = usagers_urbains.join(annee_acc, \"Num_Acc\")\n",
    "usagers_urbains = usagers_urbains.withColumn(\"age\", usagers_urbains[\"year\"] - usagers_urbains[\"An_nais\"])\n",
    "usagers_urbains.show(5)\n",
    "\n",
    "title = 'Distribution de l\\'âge des usagers qui ont eu un accident dans une route de métropole'\n",
    "\n",
    "def plot_age(df, title):\n",
    "    df_pd = df.toPandas()\n",
    "    fig = px.histogram(df_pd, x='age', title=title, labels={'age': 'Âge'})\n",
    "    fig.show()\n",
    "\n",
    "plot_age(usagers_urbains, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution de l'âge des usagers qui ont eu un accident dans les autres types de route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usagers_non_urbains = joined_usagers_lieux_df.select(\"Num_Acc\", \"id_usager\", \"sexe\",\"An_nais\").where(\"catr!=7\")\n",
    "usagers_non_urbains = usagers_non_urbains.join(annee_acc, \"Num_Acc\")\n",
    "usagers_non_urbains = usagers_non_urbains.withColumn(\"age\", usagers_non_urbains[\"year\"] - usagers_non_urbains[\"An_nais\"])\n",
    "title = 'Distribution de l\\'âge des usagers qui ont eu un accident dans les autres types de route'\n",
    "plot_age(usagers_non_urbains, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- Les jeunes dans la vingtaine sont toujours les plus touché par les accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Révisions des noms et des colonnes inutiles pour sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names_caract(df):\n",
    "    df = df.withColumnRenamed(\"lum\", \"lumière\")\n",
    "    df = df.withColumnRenamed(\"dep\", \"département\")\n",
    "    df = df.withColumnRenamed(\"com\", \"commune\")\n",
    "    df = df.withColumnRenamed(\"agg\", \"est_agglomération\")\n",
    "    df = df.withColumnRenamed(\"int\", \"intersection\")\n",
    "    df = df.withColumnRenamed(\"atm\", \"conditions_météorologiques\")\n",
    "    df = df.withColumnRenamed(\"col\", \"collision\")\n",
    "    df = df.withColumnRenamed(\"adr\", \"lieu\")\n",
    "    df = df.withColumnRenamed(\"lat\", \"latitude\")\n",
    "    df = df.withColumnRenamed(\"long\", \"longitude\")\n",
    "    return df\n",
    "\n",
    "def clean_names_usagers(df):\n",
    "    df = df.withColumnRenamed(\"num_veh\", \"numéro_vehicule\")\n",
    "    df = df.withColumnRenamed(\"catu\", \"catégorie_usager\")\n",
    "    df = df.withColumnRenamed(\"grav\", \"gravité\")\n",
    "    df = df.withColumnRenamed(\"an_nais\", \"année_naissance\")\n",
    "    df = df.withColumnRenamed(\"secu1\", \"sécurité_1\")\n",
    "    df = df.withColumnRenamed(\"secu2\", \"sécurité_2\")\n",
    "    df = df.withColumnRenamed(\"secu3\", \"sécurité_3\")\n",
    "    df = df.withColumnRenamed(\"locp\", \"localisation_piéton\")\n",
    "    df = df.withColumnRenamed(\"actp\", \"action_piéton\")\n",
    "    df = df.withColumnRenamed(\"etatp\", \"état_piéton\")\n",
    "    return df\n",
    "\n",
    "def clean_names_lieux(df):\n",
    "    df = df.withColumnRenamed(\"catr\", \"catégorie_route\")\n",
    "    df = df.withColumnRenamed(\"circ\", \"circulation\")\n",
    "    df = df.withColumnRenamed(\"nbv\", \"nombre_voies\")\n",
    "    df = df.withColumnRenamed(\"vosp\", \"voie_réservée\")\n",
    "    df = df.withColumnRenamed(\"prof\", \"profil_route\")\n",
    "    df = df.withColumnRenamed(\"pr\", \"numéro_pr\")\n",
    "    df = df.withColumnRenamed(\"pr1\", \"indice_pr\")\n",
    "    df = df.withColumnRenamed(\"plan\", \"tracé_route\")\n",
    "    df = df.withColumnRenamed(\"lartpc\", \"largeur_terre_plein_central\")\n",
    "    df = df.withColumnRenamed(\"larrout\", \"largeur_route\")\n",
    "    df = df.withColumnRenamed(\"surf\", \"surface_route\")\n",
    "    df = df.withColumnRenamed(\"infra\", \"infrastructure\")\n",
    "    df = df.withColumnRenamed(\"situ\", \"situation_accident\")  \n",
    "    df = df.withColumnRenamed(\"vma\", \"vitesse_max_autorisée\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_names_vehicules(df):\n",
    "    df = df.withColumnRenamed(\"num_veh\", \"numéro_vehicule\")\n",
    "    df = df.withColumnRenamed(\"senc\", \"sens_circulation\")\n",
    "    df = df.withColumnRenamed(\"catv\", \"catégorie_vehicule\")\n",
    "    df = df.withColumnRenamed(\"obs\", \"obstacle_fixe_heurté\")\n",
    "    df = df.withColumnRenamed(\"obsm\", \"obstacle_mobile_heurté\")\n",
    "    df = df.withColumnRenamed(\"choc\", \"point_choc_initial\")\n",
    "    df = df.withColumnRenamed(\"manv\", \"manoeuvre_principale_avant_accident\")\n",
    "    df = df.withColumnRenamed(\"motor\", \"type_motorisation\")\n",
    "    df = df.withColumnRenamed(\"occutc\", \"nombre_occupants\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def caracteristique_df_trunc_useless (df):\n",
    "    df = df.drop(\"adr\")\n",
    "    df = df.drop(\"lat\")\n",
    "    df = df.drop(\"long\")\n",
    "    df = df.drop(\"agg\")\n",
    "    df = df.drop(\"dep\")\n",
    "    df = df.drop(\"com\")\n",
    "    return df\n",
    "\n",
    "def usagers_df_trunc_useless (df):\n",
    "    df = df.drop(\"num_veh\")\n",
    "    return df\n",
    "\n",
    "def caracteristique_df_trunc(df):\n",
    "    df = df.drop(\"date_complete\").drop(\"lum\").drop(\"int\").drop(\"atm\").drop(\"col\").drop(\"adr\")\n",
    "    return df\n",
    "\n",
    "def info_lieux (df_lieux, df_caract):\n",
    "    df = df_lieux.join(caracteristique_df_trunc(df_caract), \"Num_Acc\")\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des nouveaux dataframes à sauvegarder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_l = info_lieux(lieux, caracteristiques)\n",
    "df_new_l = clean_names_lieux(df_new_l)\n",
    "df_new_l.show(5)\n",
    "\n",
    "df_new_c = caracteristique_df_trunc_useless(caracteristiques)\n",
    "df_new_c = clean_names_caract(df_new_c) \n",
    "df_new_c.show(5)\n",
    "\n",
    "df_new_u = usagers_df_trunc_useless(usagers)\n",
    "df_new_u = clean_names_usagers(df_new_u)\n",
    "df_new_u.show(5)\n",
    "\n",
    "df_new_v = clean_names_vehicules(vehicules)\n",
    "df_new_v.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix Partitionnement \n",
    "\n",
    "Le partitionnement reste le même, mais \"caractéristiques\" donne des colonnes à lieux. \n",
    "Maintenant:\n",
    "- \"caractéristiques\" donne l'environnement et la date de l'accident.\n",
    "- \"lieux\" donne l'état du lieu à l'instant de l'accident ainsi que les détails à l'endroit précis (sur une rue on peut avoir deux dénivelés différents et on enlève cette ambiguité avec la latitude et la longitude)\n",
    "\n",
    "\"caractérisques\" et lieux ne peuvent donc pas être fusionnés car plusieurs accident peuvent survenir dans le même endroit.\n",
    "\n",
    "\"usagers\" ne peut pas être fusionner avec caractérisque car un id_usager peut être associé au même Num_Acc, on évitera donc de répéter des lignes avec le join. \n",
    "\n",
    "\"vehicules\" devrait rester seul car cela permettra d'avoir les informations sur le véhicule et son comportement lors de l'accident. \n",
    "De plus, il est possible d'avoir plusieurs accidents avec le même véhicule dans la même année. Cependant \"usagers\" perd num_veh car on associe déjà avec le couple (Num_Acc, id_vehicule).\n",
    "\n",
    "\"vehicules\" et \"usagers\" gardent leur colonne id_vehicule car dans un accident on peut avoir plusieurs véhicules avec plusieurs usagers.\n",
    "\n",
    "Tous les dataframes sont l'union de l'année 2021 et 2022. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de sauvegardes Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "def create_save_parquet(df, filename):\n",
    "    if Path(filename).exists():\n",
    "        shutil.rmtree(filename)\n",
    "        df.write.parquet(filename)\n",
    "        print(\"Fichier Parquet remplacé avec succès.\")\n",
    "    else:\n",
    "        df.write.parquet(filename)\n",
    "        print(\"Fichier Parquet créé avec succès.\")\n",
    "\n",
    "create_save_parquet(df_new_l, './saves/lieux.parquet')\n",
    "create_save_parquet(df_new_c, './saves/caracteristiques.parquet')\n",
    "create_save_parquet(df_new_u, './saves/usagers.parquet')\n",
    "create_save_parquet(df_new_v, './saves/vehicules.parquet')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
